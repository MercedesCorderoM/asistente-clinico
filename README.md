# ğŸ§  Asistente ClÃ­nico (TFM)

Asistente digital clÃ­nico que:
- Graba la consulta mÃ©dica (audio).
- Transcribe automÃ¡ticamente a texto (Whisper).
- Estructura la informaciÃ³n en formato **SOAP** (Subjetivo, Objetivo, EvaluaciÃ³n, Plan).
- Ofrece soporte preliminar al diagnÃ³stico.

---

## ğŸ“‚ Estructura del proyecto
ASISTENTE-CLINICO/
â”œâ”€ asistente_frontend/ # Next.js (React + Tailwind + ShadCN UI)
â”‚ â”œâ”€ src/...
â”‚ â””â”€ package.json
â”‚
â”œâ”€ asistente-backend/ # FastAPI (Python, Whisper, spaCy)
â”‚ â”œâ”€ app/...
â”‚ â””â”€ requirements.txt
â”‚
â”œâ”€ README.md # Este archivo
â””â”€ .gitignore


---

## âš™ï¸ Requisitos previos

- **Node.js** â‰¥ 18
- **Python** 3.10 â€“ 3.12 (recomendado)
- **FFmpeg** instalado en el sistema  
  - Ubuntu/Debian: `sudo apt-get install ffmpeg`  
  - macOS: `brew install ffmpeg`  
  - Windows: `choco install ffmpeg`

---

## ğŸš€ InstalaciÃ³n y ejecuciÃ³n

### Backend (FastAPI)

```bash
cd asistente-backend
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate

pip install -r requirements.txt
pip install torch --index-url https://download.pytorch.org/whl/cpu

uvicorn app.main:app --reload --port 8000

PARA EL FRONTEND
 cd asistente_frontend
 npm install
 Crear archivo .env.local: NEXT_PUBLIC_API_URL=http://localhost:8000
 Ejecutar en desarrollo: npm run dev
 --> Frontend en: http://localhost:3000


ğŸ”„ Flujo de uso

1. Iniciar backend (FastAPI).
2 Iniciar frontend (Next.js).
3. En el navegador:
   - Pulsar Iniciar grabaciÃ³n para grabar audio y transcribirlo.
   - Editar/agregar texto en el Ã¡rea de texto.
   - Pulsar Procesar informe para estructurar en formato SOAP.

ğŸ“¦ Dependencias principales

Frontend: Next.js, React, Tailwind, ShadCN UI.

Backend: FastAPI, Whisper (openai-whisper), spaCy (es_core_news_md), PyTorch (CPU).

ğŸ” Privacidad

- Los audios se procesan localmente (no se guardan por defecto).
- Cumplimiento con RGPD: anonimizar datos y evitar persistencia salvo consentimiento expreso.